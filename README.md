<h1 align='center'>
         üîç Analisador L√©xico-Sint√°tico
</h1>

<p align="center">
  <img src="https://img.shields.io/badge/C%2B%2B-00599C?style=for-the-badge&logo=c%2B%2B&logoColor=white" alt="C++">
  <img src="https://img.shields.io/badge/GCC-orange?style=for-the-badge&logo=gnu-compiler-collection&logoColor=white" alt="GCC">
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python">
  <img src="https://img.shields.io/badge/Ubuntu-E95420?style=for-the-badge&logo=ubuntu&logoColor=white" alt="Ubuntu">
  <img src="https://img.shields.io/badge/Visual_Studio_Code-007ACC?style=for-the-badge&logo=visual-studio-code&logoColor=white" alt="Visual Studio Code">
  <img src="https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white" alt="Git">
  <img src="https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white" alt="GitHub">
  
<img src="https://img.shields.io/badge/-Makefile-red?style=for-the-badge&logo=gnu-make&logoColor=white" alt="Makefile">
<img src="https://img.shields.io/badge/doxygen-2C4AA8?style=for-the-badge&logo=doxygen&logoColor=white" alt="Doxygen"></p>
<div align='center'>
Laborat√≥rio de Algoritmos e Estruturas de Dados I <br>
Engenharia de Computa√ß√£o <br>
Prof. Michel Pires da Silva <br>
CEFET-MG Campus V <br>
2026/1  
</div>

<details>
<summary><h2>üìã √çndice</h2></summary>
</details>

## üìù Introdu√ß√£o

Este projeto foi desenvolvido como trabalho de aproveitamento da disciplina de Laborat√≥rio de Algor√≠tmos e Estruturas de Dados I (LAEDI), sob a orienta√ß√£o do professor [Michel Pires Silva](https://github.com/mpiress). Este trabalho tem como objetivo principal o desenvolvimento de um sistema denominado Analisador L√©xico-Sint√°tico (LSA), capaz de avaliar diferentes m√©tricas associadas √† qualidade textual.
O LSA √© respons√°vel por processar um texto de entrada e extrair informa√ß√µes estat√≠sticas, estruturais e sem√¢nticas sobre seu conte√∫do. A partir da leitura sequencial do texto, o sistema identifica palavras (*tokens*), express√µes compostas, senten√ßas, par√°grafos e s√≠mbolos de pontua√ß√£o, organizando esses dados por meio de estruturas de dados implementadas manualmente, como:
* Listas encadeadas (LinkedList).
* Pilhas (Stack).
* Filas (Queue).
* Tabelas hash (HashTable).
Todas as estruturas foram implementadas durante o projeto, sem o uso de bibliotecas prontas da Standard Template Library (STL), respeitando as restri√ß√µes e objetivos did√°ticos da disciplina aproveitada.
Durante o processamento do texto, o sistema realiza diversas tarefas, entre elas:
* Contagem da frequ√™ncia de palavras e express√µes.
* Identifica√ß√£o de palavras irrelevantes (*stop words*).
* Registro detalhado das ocorr√™ncias dos *tokens* (par√°grafo, senten√ßa, linha e posi√ß√£o).
* Verifica√ß√£o do balanceamento de s√≠mbolos de pontua√ß√£o.
* Gera√ß√£o de estat√≠sticas por senten√ßa e por par√°grafo.
* Constru√ß√£o da distribui√ß√£o de comprimento das palavras.
Al√©m disso, o sistema incorpora an√°lise de desempenho de algoritmos de ordena√ß√£o, comparando *MergeSort* e *QuickSort* usando diferentes comparadores e vari√°veis de ordena√ß√£o. Para cada algoritmo, s√£o coletadas as seguintes m√©tricas:
* N√∫mero de compara√ß√µes
* N√∫mero de trocas
* Tempo de execu√ß√£o
Esses dados e a distribui√ß√£o por comprimento s√£o exportados no formato `.csv` e posteriormente utilizados para plotagem de gr√°ficos com scripts em Python.
Como parte da automa√ß√£o do projeto, foi desenvolvido pensando na execu√ß√£o em *pipeline* a partir do Makefile, tendo a seguinte ordem:
1. Compila√ß√£o e cria√ß√£o dos objetos (.o) do c√≥digo em C++.
2. Execu√ß√£o do analisador sobre o texto de entrada.
3. Gera√ß√£o do ``output.txt`` e dos arquivos `.csv`.
4. Plotagem dos gr√°ficos utilizando ``pandas`` e ``matplolib`` em Python.
Os textos utilizados para testar e analisar o projeto foram Dom Casmurro e a Semana Machado de Assis, ambas obras de Machado de Assis, oferecidas inicialmente para o trabalho de aproveitamento. Estes materiais foram selecionados devido ao tamanho textual e riqueza lingu√≠stica, possibilitando executar o sistema em um cen√°rio realista e desafiador para an√°lise.
Com este trabalho, busca-se consolidar os conceitos fundamentais da disciplina de LAEDI, demonstrando o conhecimento do autor sobre a disciplina em uma aplica√ß√£o real, mensur√°vel e extens√≠vel.

## üéØObjetivos

### Objetivo Geral
O objetivo geral deste trabalho √© projetar e implementar um Analisador L√©xico-Sint√°tico para processamento de texto em linguagem natural, capaz de identificar tokens, senten√ßas, par√°grafos, express√µes e padr√≥es sint√°ticos, utilizando estruturas de dados fundamentais e algoritmos de ordena√ß√£o, com foco em corretude, eleg√¢ncia e desempenho computacional.
Busca-se aplicar, de forma pr√°tica os conceitos de Algoritmos e Estruturas de Dados I, integrando an√°lise l√©xica, controle sint√°tico b√°sico (balanceamento de s√≠mbolos) e gera√ß√£o de estat√≠sticas textuais relevantes, podendo ser relacionado a disciplinas posteriores do curso, como Linguagens de Programa√ß√£o, Linguagens Formais e Aut√¥matos e Compiladores.
#### M√©tricas de Desempenho
A avalia√ß√£o do sistema desenvolvido considera os seguintes crit√©rios:
* **Tempo de Execu√ß√£o:**
  Tempo necess√°rio para realizar a an√°lise completa do texto e executar os algoritmos de ordena√ß√£o, medido em segundos.
* **Uso de Estruturas de Dados:**
  Aplica√ß√£o correta e elegante de estruturas de dados como pilhas, filas, listas encadeadas e tabelas hash, respeitando suas caracter√≠sticas.
* **Complexidade assint√≥tica:**
  An√°lise do comportamento assint√≥tico das principais opera√ß√µes, como inser√ß√µes em tabelas hash, percursos em listas encadeadas e algoritmos de ordena√ß√£o (*MergeSort* e *QuickSort*).
* **Qualidade da An√°lise Textual:**
  Capacidade do sistema em extrair informa√ß√µes l√©xicas e estruturais relevantes, como frequ√™ncia de tokens, distribui√ß√£o de comprimento das palavras e identifica√ß√£o de express√µes.

### Objetivos Espec√≠ficos
* **Implementar um analisador l√©xico para textos em linguagem natural:**
  Identificar e normalizar tokens (palavras), removendo *stopwords*, tratando abrevia√ß√µes, n√∫meros e caracteres especiais, al√©m de registrar ocorr√™ncias detalhadas (par√°grafo, senten√ßa, linha e posi√ß√£o).
* **Realizar an√°lise sint√°tica b√°sica do texto:**
  Verificar o balanceamento de s√≠mbolos de pontua√ß√£o (par√™nteses, colchetes, chaves, aspas), utilizando estruturas de pilha, identificando inconsist√™ncias sint√°ticas.
* **Organizar informa√ß√µes textuais por senten√ßas e par√°grafos:**
  Estruturar os dados analisados em n√≠veis hier√°rquicos (texto ‚Üí par√°grafos ‚Üí senten√ßas), armazenando estat√≠sticas como n√∫mero de palavras, palavras sem *stopwords* e comprimento m√©dio, al√©m de facilitar a gest√£o das estruturas de dados globais, como a listas de tabela hash para tokens e express√µes.
* **Detectar e contabilizar express√µes pr√©-definidas:**
  Identificar express√µes compostas ao longo do texto, registrando sua frequ√™ncia e linhas de ocorr√™ncia.
* **Construir distribui√ß√µes estat√≠sticas do texto:**
  Gerar a distribui√ß√£o de comprimento das palavras, utilizando uma estrutura de mapa (`IntIntMap`) implementada sem depend√™ncia da STL.
* **Aplicar e comparar algoritmos de ordena√ß√£o:**
  Implementar e avaliar *MergeSort* e *QuickSort* para diferentes crit√©rios de ordena√ß√£o (ordem alfab√©tica e frequ√™ncia), coletando m√©tricas de compara√ß√µes, trocas e tempo de execu√ß√£o.
* **Exportar dados para an√°lise externa:**
  Gerar arquivos `.csv` contendo m√©tricas de ordena√ß√£o e distribui√ß√µes estat√≠sticas, possibilitando a visualiza√ß√£o gr√°fica por meio de scripts em Python.
* **Documentar o projeto com Doxygen:**
  Produzir documenta√ß√£o t√©cnica completa do c√≥digo-fonte, incluindo descri√ß√£o de classes, m√©todos, par√¢metros e estruturas de dados utilizadas.

## üìö Fundamenta√ß√£o Te√≥rica
O desenvolvimento de um sistema de an√°lise textual eficiente exige a aplica√ß√£o integrada de conceitos cl√°ssicos de estruturas de dados, algoritmos de ordena√ß√£o e processamento de texto. Este trabalho fundamenta-se nesses pilares para realizar a leitura, organiza√ß√£o, an√°lise estat√≠stica e apresenta√ß√£o de informa√ß√µes extra√≠das de textos extensos, respeitando crit√©rios de desempenho e uso eficiente de mem√≥ria.

A seguir, s√£o apresentados os principais conceitos te√≥ricos que embasam a implementa√ß√£o do sistema proposto.

### An√°lise l√©xica (Scanner)
√â o processo de decompor um texto ou c√≥digo-fonte em unidades m√≠nimas e significativas, denominadas *tokens* que s√£o usadas fundamentalmente em compiladores, interpretadores e em processamento de linguagem natural (PLN), para entender a estrutura e significado da entrada.

### An√°lise sint√°tica (Parser)
Tem como fun√ß√£o receber os tokens do analisador l√©xico e verificar se eles formam uma estrutura gramaticalmente correta, de acordo com as regras da linguagem. Tamb√©m s√£o fundamentais para compiladores e PLN.

### Pilhas (Stacks)
A pilha √© uma estrutura de dados baseada no princ√≠pio FILO (First In, Last Out). Os elementos s√£o inseridos e removidos sempre pelo topo.
Neste projeto, pilhas s√£o usadas para:
* Verificar o balanceamento de s√≠mbolos de pontua√ß√£o, como par√™nteses, colchetes e chaves;
* Garantir a correta correspond√™ncia entre s√≠mbolos de abertura e fechamento.

### Filas (Queues)
A fila segue o princ√≠pio FIFO (First In, First Out), em que o primeiro elemento inserido (enqueue) √© o primeiro a ser removido (dequeue).
As filas s√£o empregadas para:
* Armazenar senten√ßas e par√°grafos na ordem em que aparecem no texto;
* Garantir o processamento sequencial correto das estruturas textuais.

### Listas Encadeadas (Linked Lists)
As listas encadeadas permitem inser√ß√£o e remo√ß√£o din√¢mica de elementos, sem necessidade de realoca√ß√£o cont√≠nua de mem√≥ria. Cada elemento aponta para o pr√≥ximo, formando uma sequ√™ncia encadeada.
No contexto deste projeto, as listas encadeadas s√£o utilizadas para:
* Armazenar tokens e express√µes;
* Registrar ocorr√™ncias (linhas, posi√ß√µes, senten√ßas);
* Servir como base para estruturas mais complexas.

### Tabelas Hash (Hash Tables)
Tabelas hash s√£o estruturas de dados que permitem acesso r√°pido a elementos por meio de uma fun√ß√£o de dispers√£o (hash function). Elas oferecem, em m√©dia, complexidade de tempo constante para inser√ß√£o, busca e remo√ß√£o. A resolu√ß√£o de colis√µes √© feita por encadeamento, utilizando listas encadeadas nos buckets da tabela.
No projeto, tabelas hash s√£o utilizadas para:
* Armazenar tokens (palavras) e suas estat√≠sticas;
* Registrar express√µes e suas ocorr√™ncias;
* Evitar duplica√ß√£o de entradas;
* Facilitar consultas r√°pidas por texto.

### Mapas Associativos
Mapas associativos permitem relacionar chaves a valores. Neste trabalho, foi implementado um mapa espec√≠fico de inteiros (`IntIntMap`) sem o uso da biblioteca padr√£o STL.
Esse mapa √© utilizado para:
* Construir a distribui√ß√£o de comprimento das palavras;
* Associar o tamanho da palavra √† sua frequ√™ncia de ocorr√™ncia.

### Algoritmos de Ordena√ß√£o
A ordena√ß√£o dos dados √© essencial para a apresenta√ß√£o organizada dos resultados e para an√°lises comparativas de desempenho.
#### Merge Sort
O Merge Sort √© um algoritmo de ordena√ß√£o baseado na estrat√©gia "dividir para conquistar". Ele divide o vetor em partes menores, ordena cada parte e, em seguida, realiza a fus√£o ordenada.
Caracter√≠sticas:
* Complexidade do pior e melhor caso: $$O(n\;log\;n)$$
* Est√°vel
* Custo adicional de mem√≥ria para copiar o vetor.
* N√£o h√° melhora se os elementos j√° estiverem parcialmente ordenados.
* N√£o faz troca de elementos, pois eles se ordenam quando as partes se fundem (merge).
#### Quick Sort
O Quick Sort tamb√©m segue a estrat√©gia de "dividir para conquistar", escolhendo um piv√¥ e particionando o vetor em elementos menores e maiores que ele.
Caracter√≠sticas:
* Complexidade m√©dia: $$O(n\;log\;n)$$
* Pior caso: $$O(n^2)$$
* Inst√°vel, pode alterar a ordem dos elementos de mesmo valor.
* Custo de mem√≥ria extra relacionado a recurs√£o na pilha.
#### Merge Sort X Quick Sort
|Caracter√≠stica|**MergeSort**| **QuickSort**|
|-|-|-|
|**Estrat√©gia**|Dividir  para conquistar|Dividir  para conquistar|
|**Complexidade (Melhor Caso)**|$$O(n\;log\;n)$$|$$O(n\;log\;n)$$|
|**Complexidade (Caso M√©dio)**|$$O(n\;log\;n)$$|$$O(n\;log\;n)$$|
|**Complexidade (Pior Caso)**|$$O(n\;log\;n)$$|$$O(n^2)$$|
|**Estabilidade**|Est√°vel|Inst√°vel|
|**Adapatabilidade**|N√£o|Sim|
|**Mem√≥ria extra**|$$O(n)$$|$$O(log\;n)$$|
|**Movimenta√ß√µes (Swaps)**|$$O(n\;log\;n)$$|$$O(n\;log\;n)$$|

**Tabela comparativa das caracteriscas do Merge Sort e do Quick Sort**

## üî¨ Modelagem da Aplica√ß√£o
A partir do objetivo de desenvolver um sistema analisador l√©xico-sint√°tico, a modelagem teve como princ√≠pio equilibrar o desempenho computacional com a constru√ß√£o de um sistema robusto e modular. O projeto foi implementado em C++, visando efici√™ncia computacional, controle expl√≠cito de mem√≥ria e flexibilidade na implementa√ß√£o de estruturas personalizadas com POO.

A arquitetura do sistema segue uma abordagem modular, na qual cada componente possui responsabilidades bem definidas, facilitando tanto a manuten√ß√£o quanto a an√°lise individual de desempenho. O fluxo geral da aplica√ß√£o √© coordenado pela fun√ß√£o `main`, que orquestra a leitura do texto, a an√°lise l√©xica, o armazenamento dos dados e a gera√ß√£o dos relat√≥rios e m√©tricas experimentais.

### Fluxo de Execu√ß√£o do Sistema
O funcionamento do analisador pode ser dividido em etapas sequenciais, que refletem o *pipeline* de processamento textual adotado no projeto:
1. **Leitura do Texto de Entrada**
   O sistema inicia com a leitura do arquivo de texto fornecido via linha de comando. Essa etapa √© realizada pela classe `TextReader`, respons√°vel por:

   * Abrir e validar o arquivo de entrada;
   * Ler o texto linha a linha;
   * Manter o controle do n√∫mero da linha atual.
2. **An√°lise L√©xica**
   A etapa central do sistema √© conduzida pela classe `Analyzer`, que processa cada linha do texto e executa as seguintes opera√ß√µes:

   * Normaliza√ß√£o das palavras (remo√ß√£o de acentos, convers√£o para min√∫sculas, tratamento de caracteres especiais);
   * Identifica√ß√£o e filtragem de *stopwords*, definidas em `stopwords.txt`;
   * Tokeniza√ß√£o do texto em palavras (*tokens*);
   * Registro das ocorr√™ncias de cada token (par√°grafo, senten√ßa, linha e posi√ß√£o);
   * Detec√ß√£o de senten√ßas e par√°grafos;
   * Verifica√ß√£o do balanceamento de s√≠mbolos de pontua√ß√£o por meio de pilhas;
   * Identifica√ß√£o e contagem de express√µes previamente definidas em `expressoes.txt`.
3. **Armazenamento em Estruturas de Dados**
   Ainda na class ``Analyzer``, os dados extra√≠dos durante a an√°lise s√£o armazenados utilizando estruturas implementadas manualmente no projeto, tais como:

   * Tabelas hash para tokens e express√µes;
   * Listas encadeadas para armazenar cole√ß√µes din√¢micas;
   * Filas para preservar a ordem de senten√ßas e par√°grafos;
   * Pilhas para an√°lise de balanceamento de s√≠mbolos.
4. **Gera√ß√£o de Relat√≥rios e Exporta√ß√£o de Dados**
   A classe `Report` √© respons√°vel por:

   * Gerar relat√≥rios textuais detalhados com os resultados da an√°lise;
   * Exportar m√©tricas de desempenho e distribui√ß√µes estat√≠sticas em arquivos `.csv`;
   * Produzir dados que posteriormente s√£o utilizados para a gera√ß√£o de gr√°ficos.
5. **Visualiza√ß√£o Gr√°fica (P√≥s-processamento)**
   Scripts auxiliares em Python utilizam os arquivos `.csv` gerados para:

   * Plotar gr√°ficos de distribui√ß√£o do comprimento das palavras;
   * Comparar o desempenho dos algoritmos de ordena√ß√£o em fun√ß√£o do tamanho da entrada.

Essa separa√ß√£o permite o desenvolvimento e teste modular da aplica√ß√£o, al√©m de facilitar a manuten√ß√£o e refatora√ß√£o do c√≥digo, caso necess√°rio.
```mermaid
---
config:
  layout: fixed
---
flowchart TB
    A["main - Entrada do programa"] --> B["TextReader - Inicializa com arquivo de entrada passado por parametro"]
    B --> C["Analyzer - Inicializa com os arquivos de express√µes e stopwords"]
    C --> D["Analyzer - Inicia an√°lise com reader"]
    D --> E{"Existe pr√≥xima linha?"}
    E -- Sim --> F1["Verifica se tem express√£o na linha atual"]
    F1 --> F2{"Fim do par√°grafo?"}
    F2 -- Sim --> F3["Salva par√°grafo na fila de par√°grafos"]
    F3 --> E
    F2 -- N√£o --> F4{"Ainda h√° caracteres na linha?"}
    F4 -- Sim --> F5{"Caractere de pontua√ß√£o?"}
    F5 -- Sim --> F6["Adiciona √† pilha de caracteres e verifica se tem par"]
    F6 --> F4
    F5 -- N√£o --> F7{"Caractere de palavra?"}
    F7 -- Sim --> F8["Adiciona palavra √† HashTable de par√°grafo"]
    F8 --> F4
    F7 -- N√£o --> F9["Normaliza palavra atual"]
    F9 --> F10{"√â uma stopword?"}
    F10 -- Sim --> F11{"√â o fim da senten√ßa?"}
    F10 -- N√£o --> F12["Adiciona na HashTable global e de par√°grafo"]
    F12 --> F11
    F11 -- Sim --> F13["Adiciona a senten√ßa na fila de senten√ßas"]
    F13 --> F4
    F11 -- N√£o --> F4
    F4 -- N√£o --> E
    E -- N√£o --> G["Gerar IntIntMap para distribui√ß√£o por comprimento"]
    G --> H["Executa o benchmark de ordena√ß√£o"]
    H --> I["Report - Cria arquivo output.txt e arquivos .csv"]
    I --> J["Scripts Python plotam os gr√°ficos de m√©tricas e distribui√ß√£o"]
    J --> K["Fim"]
```
**Fluxograma de execu√ß√£o do projeto.**

### üìä Estruturas de Dados

O projeto faz uso extensivo de estruturas de dados implementadas manualmente, evitando o uso direto de containers prontos da STL para fins educacionais. Entre as principais estruturas utilizadas, destacam-se:

* **Lista Encadeada (`LinkedList`)**
  Utilizada como base para diversas outras estruturas, permitindo armazenamento din√¢mico de elementos. Utiliza o recurso de templates do C++, tornando-a uma estrutura gen√©rica, podendo listar qualquer tipo de elemento. Possui complexidade de inser√ß√£o, remo√ß√£o e acesso de O(n).

* **Tabela Hash (`HashTable`)**
  Empregada para armazenar tokens e express√µes, permitindo acesso eficiente por chave textual. Tamb√©m utiliza de template, por√©m √© generalizada somente para elementos que possuem o m√©todo `addOccurrence`. Possui complexidade de inser√ß√£o e acesso O(1) no melhor caso e O(n) no pior caso, sendo n o tamanho do *bucket*.

* **Fila (`Queue`)**
  Utilizada para manter a ordem de senten√ßas e par√°grafos durante o processamento e a gera√ß√£o de relat√≥rios. Possui complexidade de inser√ß√£o, acesso e remo√ß√£o O(1), gra√ßas aos ponteiros de `front` e `rear`.

* **Pilha (`Stack`)**
  Aplicada na verifica√ß√£o do balanceamento de s√≠mbolos de pontua√ß√£o, como par√™nteses e colchetes. Possui complexidade de inser√ß√£o, acesso e remo√ß√£o O(1).

* **Mapeamento Inteiro‚ÄìInteiro (`IntIntMap`)**
  Utilizado para armazenar distribui√ß√µes estat√≠sticas, como a frequ√™ncia de palavras por comprimento. Possui inser√ß√£o e acesso O(1).

Essas estruturas foram projetadas visando clareza conceitual, efici√™ncia e integra√ß√£o com os algoritmos de ordena√ß√£o e an√°lise estat√≠stica.

### üöÄ Otimiza√ß√µes Propostas

#### Pr√©-processamento Textual

* Normaliza√ß√£o antecipada das palavras para reduzir compara√ß√µes redundantes;
* Remo√ß√£o de *stopwords* ainda na fase de an√°lise, reduzindo o volume de dados armazenados.

#### Uso de Hashing

* Utiliza√ß√£o de fun√ß√£o hash simples e eficiente para distribui√ß√£o uniforme dos tokens;
* Redu√ß√£o do custo m√©dio de inser√ß√£o e busca na tabela de s√≠mbolos.

#### An√°lise Emp√≠rica de Ordena√ß√£o

* Execu√ß√£o de m√∫ltiplos testes com diferentes tamanhos de entrada;
* Compara√ß√£o entre MergeSort e QuickSort sob diferentes crit√©rios de ordena√ß√£o;
* Coleta detalhada de m√©tricas para valida√ß√£o emp√≠rica das complexidades assint√≥ticas esperadas.